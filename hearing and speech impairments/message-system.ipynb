{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import shutil\n",
    "import librosa\n",
    "import difflib\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np \n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from datasets import load_dataset, Dataset, Audio\n",
    "from speechbrain.pretrained import SepformerSeparation as separator\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline, \\\n",
    "                         WhisperProcessor, WhisperForConditionalGeneration\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = separator.from_hparams(\n",
    "                                source=\"speechbrain/sepformer-wham-enhancement\", \n",
    "                                savedir='pretrained_models/sepformer-wham-enhancement'\n",
    "                                )\n",
    "\n",
    "s2t_processor = Wav2Vec2Processor.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")\n",
    "s2t_model = Wav2Vec2ForCTC.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")\n",
    "\n",
    "zsc_pipeline = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "sin_s2t_processor = WhisperProcessor.from_pretrained(\"Subhaka/whisper-small-Sinhala-Fine_Tune\")\n",
    "sin_s2t_model = WhisperForConditionalGeneration.from_pretrained(\"Subhaka/whisper-small-Sinhala-Fine_Tune\")\n",
    "sin_s2t_forced_decoder_ids = sin_s2t_processor.get_decoder_prompt_ids(\n",
    "                                                                    language=\"sinhala\", \n",
    "                                                                    task=\"transcribe\"\n",
    "                                                                    )\n",
    "\n",
    "API_URL_DENOISER = \"https://api-inference.huggingface.co/models/speechbrain/sepformer-wsj03mix\"\n",
    "headers_DENOISER = {\"Authorization\": \"Bearer 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\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3toWav(audioFile):\n",
    "    audioFileNew = audioFile.replace('mp3', 'wav') if audioFile.endswith('.mp3') else audioFile.replace('ogg', 'wav').replace('/mp3/', '/wav/')\n",
    "    if os.path.exists(audioFileNew):\n",
    "        os.remove(audioFileNew)\n",
    "\n",
    "    if audioFile.endswith('.mp3'):\n",
    "        sound = AudioSegment.from_mp3(audioFile)\n",
    "        sound.export(audioFileNew, format=\"wav\")\n",
    "    else:\n",
    "        sound = AudioSegment.from_file(audioFile)\n",
    "        sound.export(audioFileNew, format=\"wav\")\n",
    "    return audioFileNew\n",
    "\n",
    "def audio_denoising(audioFileNew):\n",
    "    try:\n",
    "        denoiser.separate_file(path=audioFileNew) \n",
    "        file_path = os.path.split(audioFileNew)[-1]\n",
    "\n",
    "        enhancedAudioFile = audioFileNew.replace('/wav/', '/denoised_wav/')\n",
    "        if os.path.exists(enhancedAudioFile):\n",
    "            os.remove(enhancedAudioFile)\n",
    "            \n",
    "        shutil.move(file_path, enhancedAudioFile)\n",
    "        return enhancedAudioFile\n",
    "    \n",
    "    except:\n",
    "        os.remove(os.path.split(audioFileNew)[-1])\n",
    "        return audioFileNew \n",
    "\n",
    "# def remove_punc(predicted_number):\n",
    "#     predicted_number = predicted_number.replace('.', ' ')\n",
    "#     predicted_number = predicted_number.replace(',', ' ')\n",
    "#     predicted_number = predicted_number.replace('?', ' ')\n",
    "#     predicted_number = predicted_number.replace('!', ' ')\n",
    "#     predicted_number = predicted_number.replace('-', ' ')\n",
    "#     predicted_number = predicted_number.replace('_', ' ')\n",
    "#     predicted_number = predicted_number.replace(';', ' ')\n",
    "#     predicted_number = predicted_number.replace(':', ' ')\n",
    "#     predicted_number = predicted_number.replace('(', ' ')\n",
    "#     predicted_number = predicted_number.replace(')', ' ')\n",
    "#     predicted_number = predicted_number.replace('[', ' ')\n",
    "#     predicted_number = predicted_number.replace(']', ' ')\n",
    "#     predicted_number = predicted_number.replace('{', ' ')\n",
    "#     predicted_number = predicted_number.replace('}', ' ')\n",
    "#     predicted_number = predicted_number.replace('/', ' ')\n",
    "#     predicted_number = predicted_number.replace('\\\\', ' ')\n",
    "#     predicted_number = predicted_number.replace('|', ' ')\n",
    "#     predicted_number = predicted_number.replace('\\'', ' ')\n",
    "#     predicted_number = predicted_number.replace('\\\"', ' ')\n",
    "#     predicted_number = predicted_number.replace('~', ' ')\n",
    "#     return predicted_number\n",
    "\n",
    "# def speech2text(audioFile):\n",
    "#     r = sr.Recognizer()\n",
    "#     with sr.AudioFile(audioFile) as source:\n",
    "#         audio = r.record(source)\n",
    "#     text = r.recognize_google(audio)\n",
    "#     return text\n",
    "\n",
    "# def speech2number(\n",
    "#                 audioFile,\n",
    "#                 use_hf = True\n",
    "#                 ):\n",
    "    \n",
    "#     word2num = {\n",
    "#                 'one': 1,\n",
    "#                 'two or to': 2,\n",
    "#                 'three': 3,\n",
    "#                 'four': 4,\n",
    "#                 'five': 5,\n",
    "#                 'six': 6,\n",
    "#                 'seven': 7,\n",
    "#                 'eight': 8,\n",
    "#                 'nine': 9\n",
    "#                 }\n",
    "\n",
    "#     if not use_hf:\n",
    "#         r = sr.Recognizer()\n",
    "#         with sr.AudioFile(audioFile) as source:\n",
    "#             audio = r.record(source)\n",
    "#         text = r.recognize_google(audio)\n",
    "#         return text\n",
    "    \n",
    "#     else:\n",
    "#         speech_array, _ = librosa.load(audioFile, sr=16_000)\n",
    "#         inputs = s2t_processor(\n",
    "#                                 speech_array, \n",
    "#                                 sampling_rate=16_000, \n",
    "#                                 return_tensors=\"pt\", \n",
    "#                                 padding=True\n",
    "#                                 )\n",
    "#         with torch.no_grad():\n",
    "#             logits = s2t_model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "#             predicted_ids = torch.argmax(logits, dim=-1)\n",
    "#             predicted_number = s2t_processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "#         predicted_number = remove_punc(predicted_number)\n",
    "#         predicted_number = predicted_number.split(' ')\n",
    "#         if len(predicted_number) in [9, 10]:\n",
    "#                 if len(predicted_number) == 10:\n",
    "#                     predicted_number = predicted_number[1:]\n",
    "#                 predicted_number = [p.strip() for p in predicted_number]\n",
    "#                 pred_json = zsc_pipeline(\n",
    "#                                             predicted_number, \n",
    "#                                             candidate_labels = [\n",
    "#                                                                 'one',\n",
    "#                                                                 'two or to',\n",
    "#                                                                 'three',\n",
    "#                                                                 'four',\n",
    "#                                                                 'five',\n",
    "#                                                                 'six',\n",
    "#                                                                 'seven',\n",
    "#                                                                 'eight',\n",
    "#                                                                 'nine'\n",
    "#                                                                 ])\n",
    "#                 pred_numbers = []\n",
    "#                 for p in pred_json:\n",
    "#                     labels = p['labels']\n",
    "#                     scores = p['scores']\n",
    "#                     max_score = max(scores)\n",
    "#                     label = labels[scores.index(max_score)]\n",
    "#                     pred_numbers.append(word2num[label])\n",
    "\n",
    "#                 pred_numbers = '0' + ''.join([str(p) for p in pred_numbers])\n",
    "#                 pred_numbers = pred_numbers.replace(' ', '')\n",
    "#                 return pred_numbers\n",
    "#         else:\n",
    "#             print(\"Invalid number. only contains {} digits\".format(len(predicted_number)))\n",
    "#             return None\n",
    "        \n",
    "def speech2number(phone_number_text):\n",
    "    phone_number = ''\n",
    "    for word in phone_number_text.split(' '):\n",
    "        word = difflib.get_close_matches(word, ['බින්දුව', 'බින්දුවයි',\n",
    "                                            'එක' , 'එකයි' ,\n",
    "                                            'දෙක' ,  'දෙකයි' ,\n",
    "                                            'තුන' , 'තුනයි' ,\n",
    "                                            'හතර' , 'හතරයි' ,\n",
    "                                            'පහ' , 'පහයි' ,\n",
    "                                            'හය', 'හයයි',\n",
    "                                            'හත', 'හතයි',\n",
    "                                            'අට', 'අටයි',\n",
    "                                            'නවය', 'නවයයි'])[0]\n",
    "        if word in ['බින්දුව', 'බින්දුවයි']:\n",
    "            phone_number += '0'\n",
    "        elif word in ['එක' , 'එකයි']:\n",
    "            phone_number += '1'\n",
    "        elif word in ['දෙක' ,  'දෙකයි']:\n",
    "            phone_number += '2'\n",
    "        elif word in ['තුන' , 'තුනයි']:\n",
    "            phone_number += '3'\n",
    "        elif word in ['හතර' , 'හතරයි']:\n",
    "            phone_number += '4'\n",
    "        elif word in ['පහ' , 'පහයි']:\n",
    "            phone_number += '5'\n",
    "        elif word in ['හය', 'හයයි']:\n",
    "            phone_number += '6'\n",
    "        elif word in ['හත', 'හතයි']:\n",
    "            phone_number += '7'\n",
    "        elif word in ['අට', 'අටයි']:\n",
    "            phone_number += '8'\n",
    "        elif word in ['නවය', 'නවයයි']:\n",
    "            phone_number += '9'\n",
    "    return phone_number\n",
    "        \n",
    "def enhance_audio(\n",
    "                 audio_file,\n",
    "                 decible_increment = 10\n",
    "                 ):\n",
    "    audio_file = audio_file.replace('\\\\', '/')\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(audio_file)\n",
    "    except:\n",
    "        print(\"Error in reading audio file: {}\".format(audio_file))\n",
    "\n",
    "    audio = audio.low_pass_filter(1000)\n",
    "    audio = audio.high_pass_filter(1000)\n",
    "    audio = audio + decible_increment\n",
    "    \n",
    "    if ('/denoised_wav/' in audio_file):\n",
    "        audioFileEnhanced = audio_file.replace('/denoised_wav/', '/enhanced_wav/')\n",
    "        if os.path.exists(audioFileEnhanced):\n",
    "            os.remove(audioFileEnhanced)\n",
    "    else:\n",
    "        audioFileEnhanced = audio_file\n",
    "\n",
    "    file_name = os.path.split(audio_file)[-1].split('.')[0]\n",
    "    file_name_enhnaced = file_name.split('_')[0] + '_' + str(uuid.uuid4())\n",
    "    audioFileEnhanced = audioFileEnhanced.replace(file_name, file_name_enhnaced)\n",
    "    audio.export(audioFileEnhanced, format=\"wav\")\n",
    "    return audioFileEnhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audio_file):\n",
    "\n",
    "    audio_data = Dataset.from_dict(\n",
    "                                    {\"audio\": [audio_file]}\n",
    "                                    ).cast_column(\"audio\", Audio())\n",
    "    audio_data = audio_data.cast_column(\n",
    "                                        \"audio\", \n",
    "                                        Audio(sampling_rate=16000)\n",
    "                                        )\n",
    "    audio_data = audio_data[0]['audio']['array']\n",
    "    return audio_data\n",
    "\n",
    "def speech2text(audio_file):\n",
    "    audio_data = load_audio(audio_file)\n",
    "    input_features = sin_s2t_processor(\n",
    "                                audio_data, \n",
    "                                sampling_rate=16000, \n",
    "                                return_tensors=\"pt\"\n",
    "                                ).input_features\n",
    "    predicted_ids = sin_s2t_model.generate(\n",
    "                                    input_features, \n",
    "                                    forced_decoder_ids=sin_s2t_forced_decoder_ids\n",
    "                                    )\n",
    "    \n",
    "    # transcription = s2t_processor.batch_decode(predicted_ids)\n",
    "    transcription = sin_s2t_processor.batch_decode(\n",
    "                                                predicted_ids, \n",
    "                                                skip_special_tokens=True\n",
    "                                                )\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_number_pipeline(audioFile):\n",
    "    if audioFile.endswith('.mp3') or audioFile.endswith('.ogg'):\n",
    "        audioFileNew = mp3toWav(audioFile)\n",
    "    else:\n",
    "        audioFileNew = audioFile\n",
    "    enhancedAudioFile = audio_denoising(audioFileNew)\n",
    "    transcription = speech2text(enhancedAudioFile)\n",
    "    number = speech2number(transcription)\n",
    "    return number\n",
    "\n",
    "def preprocessing_speech_pipeline(audioFile):\n",
    "    if audioFile.endswith('.mp3') or audioFile.endswith('.ogg'):\n",
    "        audioFileNew = mp3toWav(audioFile)\n",
    "    else:\n",
    "        audioFileNew = audioFile\n",
    "    enhancedAudioFile = audio_denoising(audioFileNew)\n",
    "    text = speech2text(enhancedAudioFile)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0705082391'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = preprocessing_number_pipeline('data/audio_store/mp3/7.ogg')\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_answer_recognition(audioFile):\n",
    "    text = preprocessing_speech_pipeline(audioFile)\n",
    "    word = difflib.get_close_matches(\n",
    "                                    text, [\n",
    "                                            'ඔව්', 'ඕඕ', 'හරි',\n",
    "                                            'නෑ', 'නැහැ', 'නැත', 'එපා'\n",
    "                                            ])\n",
    "    if len(word) > 0:\n",
    "        word = word[0]\n",
    "        if word in ['ඔව්', 'ඕඕ', 'හරි']:\n",
    "            return 'ඔව්'\n",
    "        elif word in ['නෑ', 'නැහැ', 'නැත', 'එපා']:\n",
    "            return 'නැත'\n",
    "        \n",
    "    else:\n",
    "        if ('ඔ' in text) or ('ඕ' in text) or ('හ' in text):\n",
    "            return 'ඔව්'\n",
    "        elif ('නෑ' in text) or ('නැ' in text) or ('එ' in text):\n",
    "            return 'නැත'\n",
    "        \n",
    "    return np.random.choice(['ඔව්', 'නැත'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ඔව්'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_answer_recognition('data/audio_store/wav/OW2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
