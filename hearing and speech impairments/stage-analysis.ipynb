{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pyannote.audio import Model, Inference\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model.from_pretrained(\n",
    "                                        \"pyannote/embedding\", \n",
    "                                        use_auth_token=\"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\"\n",
    "                                        )\n",
    "embedding_inference = Inference(\n",
    "                                embedding_model, \n",
    "                                window=\"whole\"\n",
    "                                )\n",
    "\n",
    "class_dict = {\n",
    "            'Stage 1': 0,\n",
    "            'Stage 2': 1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(audio_dir='data/speech_therapy'):\n",
    "    voice_files = glob.glob(f'{audio_dir}/*/*.wav')\n",
    "    voice_files = [voice_file.replace('\\\\', '/') for voice_file in voice_files]\n",
    "\n",
    "    folder_names = [voice_file.split('/')[-2] for voice_file in voice_files]\n",
    "    labels = [class_dict[folder_name] for folder_name in folder_names]\n",
    "\n",
    "    embeddings = np.zeros((len(voice_files), 512))\n",
    "    labels = np.array(labels)\n",
    "    errorneous_idxs = []\n",
    "    for i, voice_file in enumerate(voice_files):\n",
    "        try:\n",
    "            embeddings[i] = embedding_inference(voice_file)\n",
    "        except:\n",
    "            errorneous_idxs.append(i)\n",
    "            print('Errorneous file: ', voice_file)\n",
    "\n",
    "    embeddings = np.delete(embeddings, errorneous_idxs, axis=0)\n",
    "    labels = np.delete(labels, errorneous_idxs, axis=0)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape:  (14, 512)\n",
      "labels    shape:  (14,)\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels = load_dataset()\n",
    "\n",
    "print(\"Embedding shape: \", embeddings.shape)\n",
    "print(\"labels    shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(512,))\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='detection')(x)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "                            inputs=inputs, \n",
    "                            outputs=outputs\n",
    "                            )\n",
    "    model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[\n",
    "                        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                        tf.keras.metrics.Precision(name='precision'),\n",
    "                        tf.keras.metrics.Recall(name='recall'),\n",
    "                        tf.keras.metrics.AUC(name='auc')\n",
    "                        ]\n",
    "                )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " detection (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,489\n",
      "Trainable params: 175,041\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1473 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1981 - accuracy: 0.8571 - precision: 0.7500 - recall: 0.7500 - auc: 0.9750\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1644 - accuracy: 0.9286 - precision: 1.0000 - recall: 0.7500 - auc: 1.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1052 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0886 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2715 - accuracy: 0.9286 - precision: 1.0000 - recall: 0.7500 - auc: 0.9500\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1607 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1126 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0880 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1135 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1532 - accuracy: 0.9286 - precision: 0.8000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1207 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5506 - accuracy: 0.8571 - precision: 0.7500 - recall: 0.7500 - auc: 0.8500\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0797 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1206 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1677 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2002 - accuracy: 0.9286 - precision: 0.8000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1330 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1198 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1207 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3387 - accuracy: 0.8571 - precision: 0.6667 - recall: 1.0000 - auc: 0.9750\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0661 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0694 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0868 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1224 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0648 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2960 - accuracy: 0.9286 - precision: 0.8000 - recall: 1.0000 - auc: 0.9625\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1220 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0835 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0555 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0901 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0583 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0874 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1038 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0725 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0642 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0793 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0433 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0713 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1238 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0676 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0827 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0524 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3702 - accuracy: 0.8571 - precision: 0.6667 - recall: 1.0000 - auc: 0.9250\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0400 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1531 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0592 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0605 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0700 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1168 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1214 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1524 - accuracy: 0.9286 - precision: 0.8000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0463 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0723 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0496 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "        embeddings,\n",
    "        labels,\n",
    "        epochs=100,\n",
    "        batch_size=8,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                                            monitor='loss',\n",
    "                                            patience=10,\n",
    "                                            restore_best_weights=True\n",
    "                                            )\n",
    "            ]   \n",
    "        )\n",
    "model.save('feature_store/speech therapy.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict_speech = {\n",
    "                    'Stage 1': 0,\n",
    "                    'Stage 2': 1\n",
    "                    }\n",
    "class_dict_speech_rev = {\n",
    "                        0: 'Stage 1',\n",
    "                        1: 'Stage 2'\n",
    "                        }\n",
    "\n",
    "model_speech_therapy = tf.keras.models.load_model('feature_store/speech therapy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_stage_sentiment(audio_file):\n",
    "    embedding = embedding_inference(audio_file)\n",
    "    embedding = np.expand_dims(embedding, axis=0)\n",
    "    sentiment = model.predict(embedding)\n",
    "    sentiment = sentiment.squeeze()\n",
    "    sentiment = np.round(sentiment)\n",
    "    sentiment = int(sentiment)\n",
    "    return class_dict_speech_rev[sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Stage 1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = inference_stage_sentiment('data/speech_therapy/Stage 1/s 2 48000 1-[AudioTrimmer.com].wav')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
